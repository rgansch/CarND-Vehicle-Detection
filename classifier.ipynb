{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "[Implementation](./classifier.py)\n",
    "[Configuration](./Classifier.ini)\n",
    "\n",
    "The classifier class implements the learning from a feature vector set and predition for a feature vector. It also includes a X_scaler which is automatically fit upon training the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing image data\n",
    "First we need to load all the vehicle and non-vehicle image data and extract the feature vectors from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load vehicle images\n",
      "Wall time: 3.44 s\n",
      "Load non-vehicle images\n",
      "Wall time: 3.42 s\n",
      "Convert to feature vector\n",
      "Wall time: 31.1 s\n",
      "Vehicle images: 8792\n",
      "Non-Vehicle images: 8968\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from images import ImageLoader\n",
    "from featureextractor import FeatureExtractor\n",
    "\n",
    "img_load = ImageLoader()\n",
    "feat_ext = FeatureExtractor()\n",
    "\n",
    "print('Load vehicle images')\n",
    "%time images_vehicle = img_load.get_all('train_vehicle')\n",
    "print('Load non-vehicle images')\n",
    "%time images_nonvehicle = img_load.get_all('train_non-vehicle')\n",
    "\n",
    "label_vehicle = np.ones(images_vehicle.shape[0])\n",
    "label_nonvehicle = np.zeros(images_nonvehicle.shape[0])\n",
    "\n",
    "img_set = np.concatenate((images_vehicle, images_nonvehicle))\n",
    "lbl_set = np.concatenate((label_vehicle, label_nonvehicle))\n",
    "\n",
    "print('Convert to feature vector')\n",
    "def features(img_set):\n",
    "    feat_set = []\n",
    "    for img in img_set:\n",
    "        feat_set.append(feat_ext.feature_vector(img))\n",
    "    feat_set = np.array(feat_set)\n",
    "    return feat_set\n",
    "%time feat_set = features(img_set)\n",
    "feat_set = np.vstack(feat_set)\n",
    "\n",
    "img_set, feat_set, lbl_set = shuffle(img_set, feat_set, lbl_set)\n",
    "\n",
    "print('Vehicle images: %d' % label_vehicle.shape[0])\n",
    "print('Non-Vehicle images: %d' % label_nonvehicle.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Support vector machine\n",
    "The first choice as classifier is a SVM. The standard [SVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) from sklearn is used with several configurations.\n",
    "\n",
    "Parameters:\n",
    "- kernel: Type of kernel to be used (linear or rbf usually)\n",
    "- c: loss factor\n",
    "\n",
    "Configurations:\n",
    "1. **kernel=rbf, c=1**\n",
    "2. kernel=rbf, c=1.5\n",
    "3. kernel=rbf, c=2\n",
    "4. kernel=linear, c=1\n",
    "5. kernel=linear, c=1.5\n",
    "6. kernel=linear, c=2\n",
    "\n",
    "Due to quite long training times for evaluation only a reduced data set is used. Later at the end of the notebook the best performing classifier is trained with the full set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Config Set 1\n",
      "Train time: 21.2s\n",
      "Accuracy: 99.50%\n",
      "Write classifier to pickle file ./classifiers/clf_svm1.pkl\n",
      "\n",
      "\n",
      "Config Set 2\n",
      "Train time: 20.3s\n",
      "Accuracy: 98.50%\n",
      "Write classifier to pickle file ./classifiers/clf_svm2.pkl\n",
      "\n",
      "\n",
      "Config Set 3\n",
      "Train time: 20.6s\n",
      "Accuracy: 98.25%\n",
      "Write classifier to pickle file ./classifiers/clf_svm3.pkl\n",
      "\n",
      "\n",
      "Config Set 4\n",
      "Train time: 9.7s\n",
      "Accuracy: 97.00%\n",
      "Write classifier to pickle file ./classifiers/clf_svm4.pkl\n",
      "\n",
      "\n",
      "Config Set 5\n",
      "Train time: 9.7s\n",
      "Accuracy: 96.50%\n",
      "Write classifier to pickle file ./classifiers/clf_svm5.pkl\n",
      "\n",
      "\n",
      "Config Set 6\n",
      "Train time: 9.6s\n",
      "Accuracy: 97.50%\n",
      "Write classifier to pickle file ./classifiers/clf_svm6.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from classifier import Classifier\n",
    "\n",
    "clf = Classifier()\n",
    "\n",
    "# Subset of training and testset for debugging\n",
    "REDUCED_SET = True\n",
    "num_train = 4000\n",
    "num_test = 400\n",
    "fr_train = num_train / lbl_set.shape[0]\n",
    "fr_test = num_test / lbl_set.shape[0]\n",
    "\n",
    "config11 = {'classifier' : {'type' : 'SVM'}, 'SVM' : {'c' : '1', 'kernel' : 'rbf'}}\n",
    "config12 = {'classifier' : {'type' : 'SVM'}, 'SVM' : {'c' : '1.5', 'kernel' : 'rbf'}}\n",
    "config13 = {'classifier' : {'type' : 'SVM'}, 'SVM' : {'c' : '2', 'kernel' : 'rbf'}}\n",
    "config14 = {'classifier' : {'type' : 'SVM'}, 'SVM' : {'c' : '1', 'kernel' : 'linear'}}\n",
    "config15 = {'classifier' : {'type' : 'SVM'}, 'SVM' : {'c' : '1.5', 'kernel' : 'linear'}}\n",
    "config16 = {'classifier' : {'type' : 'SVM'}, 'SVM' : {'c' : '2', 'kernel' : 'linear'}}\n",
    "cfg_set = [config11, config12, config13, config14, config15, config16]\n",
    "\n",
    "accuracy = []\n",
    "time_train = []\n",
    "for cfg_idx,cfg in enumerate(cfg_set):\n",
    "    clf.set_config(cfg)\n",
    "    \n",
    "    if REDUCED_SET:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feat_set, lbl_set, train_size=fr_train, test_size=fr_test)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feat_set, lbl_set, test_size=0.1)\n",
    "\n",
    "    t_start = time.time()\n",
    "    clf.train(X_train, y_train)\n",
    "    t_end = time.time()\n",
    "    time_train.append(t_end-t_start)\n",
    "    \n",
    "    accuracy.append(clf.accuracy(X_test, y_test))\n",
    "\n",
    "    print('Config Set %d' % (cfg_idx+1))\n",
    "    print('Train time: %.1fs' % time_train[cfg_idx])\n",
    "    print('Accuracy: %.2f%%' % (accuracy[cfg_idx]*100))\n",
    "    \n",
    "    pickle_file = './classifiers/clf_svm' + str(cfg_idx+1) + '.pkl'\n",
    "    \n",
    "    print('Write classifier to pickle file %s' % pickle_file)\n",
    "    with open(pickle_file, 'wb') as fid:\n",
    "        pickle.dump(clf, fid)   \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "As second classifer a [DTC](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) is used.\n",
    "\n",
    "Parameters:\n",
    "- criterion: Maximization criterion either gini or entropy\n",
    "- min_samples_split: Minimum number of samples to perform a split\n",
    "- min_samples_leaf: Minimum number of samples in a leaf\n",
    "\n",
    "Configurations:\n",
    "1. crit=gini, split=2, leaf=1\n",
    "2. crit=gini, split=4, leaf=1\n",
    "3. crit=gini, split=2, leaf=2\n",
    "4. crit=entropy, split=2, leaf=1\n",
    "5. crit=entropy, split=3, leaf=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Config Set 1\n",
      "Train time: 138.6s\n",
      "Accuracy: 95.21%\n",
      "Write classifier to pickle file ./classifiers/clf_dt1.pkl\n",
      "\n",
      "\n",
      "Config Set 2\n",
      "Train time: 127.4s\n",
      "Accuracy: 95.38%\n",
      "Write classifier to pickle file ./classifiers/clf_dt2.pkl\n",
      "\n",
      "\n",
      "Config Set 3\n",
      "Train time: 120.1s\n",
      "Accuracy: 96.45%\n",
      "Write classifier to pickle file ./classifiers/clf_dt3.pkl\n",
      "\n",
      "\n",
      "Config Set 4\n",
      "Train time: 55.6s\n",
      "Accuracy: 95.95%\n",
      "Write classifier to pickle file ./classifiers/clf_dt4.pkl\n",
      "\n",
      "\n",
      "Config Set 5\n",
      "Train time: 52.6s\n",
      "Accuracy: 95.95%\n",
      "Write classifier to pickle file ./classifiers/clf_dt5.pkl\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from classifier import Classifier\n",
    "\n",
    "clf = Classifier()\n",
    "\n",
    "# Subset of training and testset for debugging\n",
    "REDUCED_SET = False\n",
    "num_train = 1000\n",
    "num_test = 200\n",
    "fr_train = num_train / lbl_set.shape[0]\n",
    "fr_test = num_test / lbl_set.shape[0]\n",
    "\n",
    "config21 = {'classifier' : {'type' : 'DT'}, 'DT' : {'criterion' : 'gini', 'min_samples_split' : '2', 'min_samples_leaf' : '1'}}\n",
    "config22 = {'classifier' : {'type' : 'DT'}, 'DT' : {'criterion' : 'gini', 'min_samples_split' : '4', 'min_samples_leaf' : '1'}}\n",
    "config23 = {'classifier' : {'type' : 'DT'}, 'DT' : {'criterion' : 'gini', 'min_samples_split' : '2', 'min_samples_leaf' : '2'}}\n",
    "config24 = {'classifier' : {'type' : 'DT'}, 'DT' : {'criterion' : 'entropy', 'min_samples_split' : '2', 'min_samples_leaf' : '1'}}\n",
    "config25 = {'classifier' : {'type' : 'DT'}, 'DT' : {'criterion' : 'entropy', 'min_samples_split' : '3', 'min_samples_leaf' : '1'}}\n",
    "cfg_set = [config21, config22, config23, config24, config25]\n",
    "\n",
    "accuracy = []\n",
    "time_train = []\n",
    "for cfg_idx,cfg in enumerate(cfg_set):\n",
    "    clf.set_config(cfg)\n",
    "    \n",
    "    if REDUCED_SET:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feat_set, lbl_set, train_size=fr_train, test_size=fr_test)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feat_set, lbl_set, test_size=0.1)\n",
    "    \n",
    "    t_start = time.time()\n",
    "    clf.train(X_train, y_train)\n",
    "    t_end = time.time()\n",
    "    time_train.append(t_end-t_start)\n",
    "    \n",
    "    accuracy.append(clf.accuracy(X_test, y_test))\n",
    "\n",
    "    print('Config Set %d' % (cfg_idx+1))\n",
    "    print('Train time: %.1fs' % time_train[cfg_idx])\n",
    "    print('Accuracy: %.2f%%' % (accuracy[cfg_idx]*100))\n",
    "    \n",
    "    pickle_file = './classifiers/clf_dt' + str(cfg_idx+1) + '.pkl'\n",
    "    \n",
    "    print('Write classifier to pickle file %s' % pickle_file)\n",
    "    with open(pickle_file, 'wb') as fid:\n",
    "        pickle.dump(clf, fid)   \n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save config\n",
    "Best results are achieved with a SVM Classifers with all Config Sets around 98% accuracy. The Decision Tree classifiers only achieve 96% accuracy. The **config set 1 of the SVC** is saved to the .ini file and additionally the classifiers are all dumped as pickle file for later experimentation. This allows to load only the pickle with the trained classifier, without the need to retrain it.\n",
    "\n",
    "Further it might be benefical to use a combination of 2 or more classifiers for more robust detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "Accuracy: 99.49%\n",
      "Writing to ./classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from classifier import Classifier\n",
    "\n",
    "clf = Classifier()\n",
    "\n",
    "config = config11\n",
    "clf.set_config(config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat_set, lbl_set, test_size=0.1)\n",
    "clf.train(X_train, y_train)\n",
    "print('Accuracy: %.2f%%' % (clf.accuracy(X_test, y_test)*100))\n",
    "\n",
    "pickle_file = './classifier.pkl'\n",
    "print('Writing to %s' % pickle_file)\n",
    "clf.write_config()\n",
    "\n",
    "with open(pickle_file, 'wb') as fid:\n",
    "    pickle.dump(clf, fid)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
